# Лабораторная работа №2  
**Курс:** Параллельные методы и алгоритмы  
**Тема:** Работа с библиотекой MPI  
**Цель:** Научиться писать и отлаживать распределённые приложения с использованием библиотеки MPI.

---

## Описание лабораторной работы

В данной лабораторной работе реализовано MPI-приложение, выполняющее задачу №1 из лабораторной работы №1 с использованием **динамического распределения задач** между процессами по паттерну **master/worker**.

### Особенности реализации:

- Мастер (rank 0) читает список URL из файла `urls.txt`, раздаёт задачи воркерам и собирает отчёты.
- Воркеры (rank 1…N) обрабатывают страницы:
  - скачивают HTML;
  - парсят `<img>` теги с помощью `BeautifulSoup`;
  - скачивают изображения в отдельные папки `mpi_images/rank_X`;
  - отправляют отчёт мастеру.
- Реализована **динамическая балансировка нагрузки**: быстрые воркеры получают новые задачи сразу после завершения предыдущей.
- Все процессы используют **MPI для обмена сообщениями**, нет общей памяти между процессами.

---

## Структура проекта

```
lab_2/
│
├── mpi_downloader_two.py # Основной скрипт MPI
├── urls.txt # Список URL для обработки
├── mpi_images/ # Папки с загруженными изображениями создаются автоматически
└── README.md
```


---

## Используемые библиотеки

- [mpi4py](https://mpi4py.readthedocs.io/) — MPI для Python
- [requests](https://requests.readthedocs.io/) — скачивание страниц и изображений
- [BeautifulSoup4](https://www.crummy.com/software/BeautifulSoup/) — парсинг HTML
- hashlib, os — работа с файлами и безопасными именами

---

## Запуск MPI-программы

1. Установите необходимые библиотеки:
pip install mpi4py requests beautifulsoup4

```
2. Запустим MPI-программу (например, 4 процесса):


mpiexec -n 4 python mpi_downloader_two.py
```

> Пример вывода программы

```
[MASTER] Read 10 URLs. Starting distribution to 3 workers.
[WORKER 1] Start processing https://www.example.com

[MASTER] Report from worker 2: page done, found 24, dl 23, errs 1

[MASTER] All workers finished.
[MASTER] Summary: {'pages': 10, 'images_found': 119, 'images_dl': 118, 'errors': 3}

```
 
## Контрольные вопросы

1. Какие классы систем включает таксономия Флинна?
    - SISD, SIMD, MISD, MIMD

2. Раскройте суть закона Амдала.
    - Максимальное ускорение программы пропорционально доле параллельного кода; 
      ускорение ограничено последовательной частью.

3. Укажите показатели эффективности параллельного алгоритма.
    - Скорость выполнения, ускорение (speedup), коэффициент эффективности (efficiency).

4. Как компилируются и запускаются MPI-приложения?
    - В Python: через mpiexec -n <число_процессов> python <скрипт.py>
    - В C/C++: компиляция через mpicc, запуск через mpiexec.

5. Какова структура и обязательные элементы типового MPI-приложения?
    - Инициализация MPI (MPI_Init)
    - Определение ранка и размера коммуникатора
    - Обмен сообщениями между процессами (send/recv)
    - Завершение MPI (MPI_Finalize)

6. Перечислите и опишите парные операции передачи данных в MPI.
    - Send, Recv, Ssend, Isend, Irecv — блокирующие и неблокирующие точка-точка передачи данных.

7. Перечислите и опишите коллективные операции данных в MPI.
    - Bcast — широковещательная рассылка

    - Scatter — раздача элементов массивов по процессам

    - Gather — сбор элементов от процессов

    - Reduce — свёртка данных (сумма, max и т.п.)

8. Как выполнить неблокирующий обмен данными между процессами в MPI?
    - Использовать Isend и Irecv с последующим Wait или Test.

9. Как определить время выполнения MPI-приложения?
    - MPI.Wtime() возвращает текущее время; измеряют разницу между началом и концом выполнения.


## Выводы
 - Реализовано распределённое приложение с использованием MPI.
 - Продемонстрирована динамическая балансировка нагрузки между процессами.
 - Получены навыки работы с библиотекой mpi4py и анализа параллельных алгоритмов.